{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vanilla-tf-keras-model.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K_6At2k8Hc0X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vanilla Model with Tensorflow and Keras\n",
        "\n",
        "This model endeavors to reproduce what we did with fast.ai in TensorFlow so that we can use TensorFlow.js\n",
        "\n",
        "Source: [here](https://www.tensorflow.org/alpha/tutorials/images/transfer_learning)"
      ]
    },
    {
      "metadata": {
        "id": "WHETyKI1IRiv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "CrR5-uOoIHWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "478ec61a-fdb7-4f65-c23f-b8982c5f60f8"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"TensorFlow version is \", tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version is  1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eSx7pykEIcms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "Here we need to get the data we want to use and format it properly."
      ]
    },
    {
      "metadata": {
        "id": "JQ2UCNRaIWHu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "043561c6-7adf-4f79-9395-64a9e8e19a0f"
      },
      "cell_type": "code",
      "source": [
        "data_root = tf.keras.utils.get_file(origin='http://data.vision.ee.ethz.ch/cvl/gfanelli/kinect_head_pose_db.tgz', \n",
        "                                    fname='head_pose', untar=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://data.vision.ee.ethz.ch/cvl/gfanelli/kinect_head_pose_db.tgz\n",
            "6014402560/6014398431 [==============================] - 1593s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "thRhN4fORSza",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that here we have to hard-code in the data_path, because the data_root is not quite right (not really sure why...)"
      ]
    },
    {
      "metadata": {
        "id": "827QVgXtIsrV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_path = '/root/.keras/datasets/hpdb/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nVfvADUSRpkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8f3f503b-ffca-4de7-ecd0-68559ae93d9f"
      },
      "cell_type": "code",
      "source": [
        "cal = np.genfromtxt(data_path + '01/rgb.cal', skip_footer=6); cal"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[517.679,   0.   , 320.   ],\n",
              "       [  0.   , 517.679, 240.5  ],\n",
              "       [  0.   ,   0.   ,   1.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "OYKWhtU_SZEs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let us create methods to actually extract the center of the image and try it out"
      ]
    },
    {
      "metadata": {
        "id": "lk8DXGrzJTh6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def img2txt_name(f): \n",
        "  return data_path + str(f)[:-7] + 'pose.txt'\n",
        "\n",
        "def convert_biwi(coords):\n",
        "    c1 = coords[0] * cal[0][0]/coords[2] + cal[0][2]\n",
        "    c2 = coords[1] * cal[1][1]/coords[2] + cal[1][2]\n",
        "    return np.array([c2,c1])\n",
        "\n",
        "def get_ctr(f):\n",
        "    ctr = np.genfromtxt(img2txt_name(f), skip_header=3)\n",
        "    return convert_biwi(ctr)\n",
        "  \n",
        "def get_scaled_center(f, width, height):\n",
        "  img = cv2.imread(data_path + f)\n",
        "  pt = get_ctr(f)\n",
        "  return np.array([pt[0] * (width / img.shape[0]), pt[1] * (height / img.shape[1])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wefjjLz_Qq_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3caa3dd-c950-4314-e3e5-4b507a0befda"
      },
      "cell_type": "code",
      "source": [
        "fname = '09/frame_00667_rgb.png'\n",
        "img = cv2.imread(data_path + fname)\n",
        "print(get_ip_center(fname, img.shape[0], img.shape[1]))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[263.91039223 428.58139299]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CLz3pSKVVtdu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Training and Validation Arrays"
      ]
    },
    {
      "metadata": {
        "id": "PnID1S_DMPAr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Image Data Generator with Image Augmentation\n",
        "We then need to resize the images and create a data generator, to be used for training / validation\n",
        "\n",
        "For this section, I used an additional source: [here](https://keras.io/preprocessing/image/)"
      ]
    },
    {
      "metadata": {
        "id": "9BDSwVamMQW6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_width = 160\n",
        "image_height = 120\n",
        "batch_size = 32\n",
        "\n",
        "# Rescale all images by 1./255 and apply image augmentation\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 32 using train_datagen generator\n",
        "train_generator = train_datagen.flow(x_train, y_train\n",
        "                target_size=(image_width, image_height),  \n",
        "                batch_size=batch_size,\n",
        "                # Since we need the output to be an array of ints, we will use sparse\n",
        "                class_mode='sparse')\n",
        "\n",
        "# Flow validation images in batches of 32 using test_datagen generator\n",
        "validation_generator = validation_datagen.flow(x_valid, y_valid\n",
        "                target_size=(image_width, image_height),\n",
        "                batch_size=batch_size,\n",
        "                class_mode='sparse')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}